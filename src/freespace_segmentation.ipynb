{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Freespace Segmentation Project\n",
    "In this project we are aimed to detect drivable area using semantic segmentation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have json files and images as data. Firstly I need to convert json files to freespace mask image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Json2Mask\n",
    "Define directories for the folder containing json files and for mask output folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, tqdm, json, cv2\n",
    "import numpy as np\n",
    "\n",
    "JSON_DIR = '../data/test_jsons'\n",
    "MASK_DIR  = '../data/test_masks'\n",
    "\n",
    "if not os.path.exists(MASK_DIR):\n",
    "    os.mkdir(MASK_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get json files names and sort them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "json_list = os.listdir(JSON_DIR)\n",
    "json_list.sort()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read json files and convert them to dictionary. Get image sizes for create empty mask. Define mask path using directory and json file name. Image name and mask name will same.\n",
    "In a for loop find freespace class and get exterior points in list. Draw filled polygon on empty mask using points. Save mask in dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 476/476 [00:04<00:00, 116.13it/s]\n"
     ]
    }
   ],
   "source": [
    "for json_name in tqdm.tqdm(json_list):\n",
    "    json_path = os.path.join(JSON_DIR, json_name)\n",
    "    json_file = open(json_path, 'r')\n",
    "    json_dict = json.load(json_file)\n",
    "\n",
    "    mask = np.zeros((json_dict[\"size\"][\"height\"], json_dict[\"size\"][\"width\"]), dtype=np.uint8)\n",
    "    \n",
    "    mask_path = os.path.join(MASK_DIR, json_name[:-5])\n",
    "    \n",
    "    for obj in json_dict[\"objects\"]:\n",
    "        if obj['classTitle']=='Freespace':\n",
    "            mask = cv2.fillPoly(mask, np.array([obj['points']['exterior']]), color=1)\n",
    "            \n",
    "    cv2.imwrite(mask_path, mask.astype(np.uint8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the json to mask step we can write mask on image for check. Also we will have more meaning images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mask on image\n",
    "Define directories for the folder containing masks, images, mask_on_images folder.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, cv2, tqdm\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "MASK_DIR  = '../data/test_masks'\n",
    "IMAGE_DIR = '../data/test_images'\n",
    "IMAGE_OUT_DIR = '../data/test_masked_images2'\n",
    "\n",
    "if not os.path.exists(IMAGE_OUT_DIR):\n",
    "    os.mkdir(IMAGE_OUT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "Define a function for compare mask file names and image file names. For write mask on image, every image must have a mask. For a correct comparison, we need to get filename before file type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_mask_check(image_path_list, mask_path_list):\n",
    "    for image_path, mask_path in zip(image_path_list, mask_path_list):\n",
    "        image_name = image_path.split('/')[-1].split('.')[0]\n",
    "        mask_name  = mask_path.split('/')[-1].split('.')[0]\n",
    "        assert image_name == mask_name, \"Image and mask name does not match {} - {}\".format(image_name, mask_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "Define a function for write mask on image. Firstly read all file names in the folders. After that sort both list by name for correct match. Give that lists as parameter to image_mask_check function. <br>\n",
    "In a for loop read image and mask with openCv change mask color."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_mask_on_image():\n",
    "\n",
    "    image_file_names = [f for f in listdir(IMAGE_DIR) if isfile(join(IMAGE_DIR, f))]\n",
    "    mask_file_names = [f for f in listdir(MASK_DIR) if isfile(join(MASK_DIR, f))]\n",
    "\n",
    "    image_file_names.sort()\n",
    "    mask_file_names.sort()\n",
    "\n",
    "    image_mask_check(image_file_names,mask_file_names)\n",
    "\n",
    "    for image_file_name, mask_file_name in tqdm.tqdm(zip(image_file_names, mask_file_names)):\n",
    "        image_path = os.path.join(IMAGE_DIR, image_file_name)\n",
    "        mask_path = os.path.join(MASK_DIR, mask_file_name)\n",
    "        mask  = cv2.imread(mask_path, 0).astype(np.uint8)\n",
    "        image = cv2.imread(image_path).astype(np.uint8)\n",
    "\n",
    "        mask_image = image.copy()\n",
    "        mask_image[mask == 1, :] = (255, 0, 125)\n",
    "        opac_image = (image/2 + mask_image/2).astype(np.uint8)\n",
    "        \n",
    "        cv2.imwrite(join(IMAGE_OUT_DIR, mask_file_name), opac_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call write_mask_on_image() function for check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "476it [01:39,  4.76it/s]\n"
     ]
    }
   ],
   "source": [
    "# make uncomment for create images\n",
    "#write_mask_on_image()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Preprocess\n",
    "We should to prepare data before use on model. Model accept data as a tensor format. We need to transform images and masks to tensor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Define directories for the folder containing masks and images folder.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2, torch, glob\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms as T\n",
    "from PIL import Image\n",
    "\n",
    "MASK_DIR = \"../data/test_masks\"\n",
    "IMG_DIR = \"../data/test_images\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image to tensor\n",
    "This function take four parameters. First parameter image paths, it must be list. Second parameter is output shape of image. Third parameter is selection for gpu calculation. Fourth parameter is selection for augmenting (brightness, contrast and hue) images. <br>\n",
    "This function use torchVision transform for resizing, augmenting and converting to tensor. Tensor format is [n, n_ch, w, h]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensorize_image(image_path, output_shape, cuda=False, augment=False):\n",
    "    dataset = list()\n",
    "    Transform = list()\n",
    "    \n",
    "    Transform.append(T.Resize(output_shape))\n",
    "    if augment:\n",
    "        Transform.append(T.ColorJitter(brightness=0.4, contrast=0.4, hue=0.06))\n",
    "    Transform.append(T.ToTensor())\n",
    "    Transform = T.Compose(Transform)\n",
    "\n",
    "    for file_name in image_path:\n",
    "        image = Image.open(file_name)\n",
    "        image = Transform(image)\n",
    "\n",
    "        dataset.append(image)\n",
    "\n",
    "    tensor = torch.stack(dataset)\n",
    "    if cuda:\n",
    "        tensor = tensor.cuda()\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mask to tensor\n",
    "Firstly we need to define two functions for mask to tensor. First one is create encoded mask which is included class information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One hot encode\n",
    "Mask is a grayscale image, it is include two colors black (0) and white (1 or 255). In this mask black represent background and white represent freespace. This function create labels for representing classes. [0,1] label for background, [1,0] label for freespace. Function is returns np ndarray, array format is (width, height, n classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoder(data, n_class):\n",
    "    encoded_data = np.zeros((*data.shape, n_class), dtype=np.int)\n",
    "    encoded_labels = [[0,1], [1,0]]\n",
    "    \n",
    "    for lbl in range(n_class):\n",
    "        encoded_label = encoded_labels[lbl]                   \n",
    "        numerical_class_inds = data[:,:] == lbl                            \n",
    "        encoded_data[numerical_class_inds] = encoded_label \n",
    "\n",
    "    return encoded_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "Also define a function for decode encoded data which is converts class information to image. This function returns image list as a np ndarray. We will use for show model result as an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_and_convert_image(data, n_class):\n",
    "    decoded_data_list = []\n",
    "    decoded_data = np.zeros((data.shape[2], data.shape[3]), dtype=np.int)\n",
    "\n",
    "    for tensor in data:\n",
    "        for i in range(len(tensor[0])):\n",
    "            for j in range(len(tensor[1])):\n",
    "                if (tensor[1][i,j] == 0):\n",
    "                    decoded_data[i, j] = 255\n",
    "                else: \n",
    "                    decoded_data[i, j] = 0\n",
    "        decoded_data_list.append(decoded_data)\n",
    "\n",
    "    return decoded_data_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "This function for change np ndarray format [w, h, n_ch] to [n_ch, w, h]. We need to change format for model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def torchlike_data(data):\n",
    "    n_channels = data.shape[2]\n",
    "    torchlike_data = np.empty((n_channels, data.shape[0], data.shape[1]))\n",
    "    for ch in range(n_channels):\n",
    "        torchlike_data[ch] = data[:,:,ch]\n",
    "    return torchlike_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "This function take three parameters. First parameter image paths, it must be list. Second parameter is output shape of image. Third parameter is selection for gpu calculation. <br>\n",
    "Firstly read and resize mask using openCv. After that encode mask with \"one_hot_encoder()\" function. Change array format with \"torchlike_data()\" function, because model get tensor like [n, n_ch, w, h] format. Finally convert np ndarray data to tensor with \"torch.from_numpy()\" function. Result tensor format is [n, n_classes, w, h]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensorize_mask(mask_path, output_shape ,n_class, cuda=False):\n",
    "    batch_masks = list()\n",
    "\n",
    "    for file_name in mask_path:\n",
    "        mask = cv2.imread(file_name, 0)\n",
    "        mask = cv2.resize(mask, output_shape)\n",
    "        # mask = mask / 255\n",
    "        encoded_mask = one_hot_encoder(mask, n_class)  \n",
    "        torchlike_mask = torchlike_data(encoded_mask) #[C,W,H]\n",
    "\n",
    "        batch_masks.append(torchlike_mask)      \n",
    "  \n",
    "    batch_masks = np.array(batch_masks, dtype=np.int)\n",
    "    torch_mask = torch.from_numpy(batch_masks).float()\n",
    "    if cuda:\n",
    "        torch_mask = torch_mask.cuda()\n",
    "    return torch_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Model\n",
    "I prefer U-Net model in this project because when i searching best model for semantic segmentation i saw lots of projects used U-Net model. According to my research U-Net is good on detect small objects in picture, also this model usually used on medical diseases detection.<br>\n",
    "This is my first project on deep learning, i am learning lots of new things doing this project. That's why i preferred take a working UNet model. I tried to understand how is model and training process work.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### U-Net Model\n",
    "<img src=\"../assets/unet.png\" alt=\"unet_pic\" style=\"width:400px;\"/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}